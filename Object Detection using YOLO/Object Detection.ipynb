{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9754b725",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "<a id=\"toc\"></a>\n",
    "- [1. Import Necssaries Libraries](#1)\n",
    "- [2. Load yolov3 weights and configuration](#2)\n",
    "- [3. Extract the Object names from the coco file](#3)\n",
    "- [4. load and preprocess target image](#4)\n",
    "- [5. Detect Objects in  the Image](#5)\n",
    "- [6. Draw Boundary Boxes, Write labels and probabilty of the image's objects](#6)\n",
    "- [7. Image Result](#7)\n",
    "- [8. Detect Objects in a video](#8)\n",
    "- [9. Detect Objects webcam](#9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4876d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T22:05:59.746847Z",
     "start_time": "2022-02-26T22:05:59.730250Z"
    }
   },
   "source": [
    "<a id='1'></a>\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c73617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:47.808240Z",
     "start_time": "2022-02-27T20:44:47.677742Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b655ca",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "# Load yolov3 weights and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a9bee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:48.076505Z",
     "start_time": "2022-02-27T20:44:47.808240Z"
    }
   },
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9720e031",
   "metadata": {},
   "source": [
    "download yolo_weights: https://pjreddie.com/media/files/yolov3.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26b2581",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "# Extract the Object names from the coco file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2badf42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:48.091643Z",
     "start_time": "2022-02-27T20:44:48.078754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'bicycle',\n",
       " 'car',\n",
       " 'motorbike',\n",
       " 'aeroplane',\n",
       " 'bus',\n",
       " 'train',\n",
       " 'truck',\n",
       " 'boat',\n",
       " 'traffic light',\n",
       " 'fire hydrant',\n",
       " 'stop sign',\n",
       " 'parking meter',\n",
       " 'bench',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'cow',\n",
       " 'elephant',\n",
       " 'bear',\n",
       " 'zebra',\n",
       " 'giraffe',\n",
       " 'backpack',\n",
       " 'umbrella',\n",
       " 'handbag',\n",
       " 'tie',\n",
       " 'suitcase',\n",
       " 'frisbee',\n",
       " 'skis',\n",
       " 'snowboard',\n",
       " 'sports ball',\n",
       " 'kite',\n",
       " 'baseball bat',\n",
       " 'baseball glove',\n",
       " 'skateboard',\n",
       " 'surfboard',\n",
       " 'tennis racket',\n",
       " 'bottle',\n",
       " 'wine glass',\n",
       " 'cup',\n",
       " 'fork',\n",
       " 'knife',\n",
       " 'spoon',\n",
       " 'bowl',\n",
       " 'banana',\n",
       " 'apple',\n",
       " 'sandwich',\n",
       " 'orange',\n",
       " 'broccoli',\n",
       " 'carrot',\n",
       " 'hot dog',\n",
       " 'pizza',\n",
       " 'donut',\n",
       " 'cake',\n",
       " 'chair',\n",
       " 'sofa',\n",
       " 'pottedplant',\n",
       " 'bed',\n",
       " 'diningtable',\n",
       " 'toilet',\n",
       " 'tvmonitor',\n",
       " 'laptop',\n",
       " 'mouse',\n",
       " 'remote',\n",
       " 'keyboard',\n",
       " 'cell phone',\n",
       " 'microwave',\n",
       " 'oven',\n",
       " 'toaster',\n",
       " 'sink',\n",
       " 'refrigerator',\n",
       " 'book',\n",
       " 'clock',\n",
       " 'vase',\n",
       " 'scissors',\n",
       " 'teddy bear',\n",
       " 'hair drier',\n",
       " 'toothbrush']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = []\n",
    "with open('coco.names.txt', 'r') as Obj_Names:\n",
    "    classes = Obj_Names.read().splitlines()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d8ff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We have 80 classes , will be used to Object detection in our project\n"
     ]
    }
   ],
   "source": [
    "print(f\" We have {len(classes)} classes , will be used to Object detection in our project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b0401",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "# load, preprocess and test target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be32ace4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:48.107433Z",
     "start_time": "2022-02-27T20:44:48.093467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(277, 480, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"image1.jpg\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94e2b26a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:48.122614Z",
     "start_time": "2022-02-27T20:44:48.109426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height of the image: 277, width: 480, channels: 3\n"
     ]
    }
   ],
   "source": [
    "height, width, channels = img.shape\n",
    "print(f\"Height of the image: {height}, width: {width}, channels: {channels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9bc4f87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:48.137551Z",
     "start_time": "2022-02-27T20:44:48.123613Z"
    }
   },
   "outputs": [],
   "source": [
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "# that function is used to create a blob that is the format which their deep learning models accepts as its inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62ccc0ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:48.153257Z",
     "start_time": "2022-02-27T20:44:48.138294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.01176471, 0.01568628, 0.00784314, ..., 0.02352941,\n",
       "          0.02352941, 0.01960784],\n",
       "         [0.00784314, 0.01176471, 0.00784314, ..., 0.02352941,\n",
       "          0.01960784, 0.01960784],\n",
       "         [0.0627451 , 0.07450981, 0.07450981, ..., 0.05882353,\n",
       "          0.0509804 , 0.05490196],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.00784314, 0.01176471, 0.00392157, ..., 0.00784314,\n",
       "          0.00392157, 0.        ],\n",
       "         [0.00392157, 0.00784314, 0.00392157, ..., 0.00784314,\n",
       "          0.00392157, 0.        ],\n",
       "         [0.0627451 , 0.07058824, 0.07058824, ..., 0.03921569,\n",
       "          0.03137255, 0.03529412],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.00784314, 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.00392157, 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.05882353, 0.0627451 , 0.0627451 , ..., 0.03137255,\n",
       "          0.02745098, 0.03137255],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4cec95",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "# Detect Objects in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "494c5445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:48.613713Z",
     "start_time": "2022-02-27T20:44:48.155284Z"
    }
   },
   "outputs": [],
   "source": [
    "net.setInput(blob) # set the input from the blob into the network\n",
    "output_layers_names = net.getUnconnectedOutLayersNames() # get the output layers names\n",
    "layersOutput = net.forward(output_layers_names) # passing output layers names to forward network function we will get the output from this funciton\n",
    "boundary_boxes = []\n",
    "probabilities = []\n",
    "predicted_classes = []\n",
    "for output in layersOutput: # extract all the information from the layers output\n",
    "    for detection in output: # extract the information from each of the outputs\n",
    "        scores = detection[5:] # store all the acting classes predictions \n",
    "        class_id = np.argmax(scores) # store the locations that contains the higher scores\n",
    "        probability = scores[class_id] # extract the higher scores,\n",
    "        # bec. we want to make sure that thier their predictions has a confidence that is high enough to consider that the object has been detected\n",
    "        if probability > 0.5:\n",
    "            center_x = int(detection[0]*width) # scale it back\n",
    "            center_y = int(detection[1]*height)\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "            # bec. yolo predicts the results with the center of the bounding boxes\n",
    "            # extract the upper left cornor position\n",
    "            x = int(center_x- w/2)\n",
    "            y = int(center_y- h/2)\n",
    "            boundary_boxes.append([x,y,w,h])\n",
    "            probabilities.append((float(probability)))\n",
    "            predicted_classes.append(class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6c5b0c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:48.629683Z",
     "start_time": "2022-02-27T20:44:48.617714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(boundary_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655d505b",
   "metadata": {},
   "source": [
    "**handle more than one boundry box for the same object by using non maximum suppression function**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ce1cb5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:48.644752Z",
     "start_time": "2022-02-27T20:44:48.632675Z"
    }
   },
   "outputs": [],
   "source": [
    "indexes = cv2.dnn.NMSBoxes(boundary_boxes, probabilities, 0.5, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e63a7da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:48.660713Z",
     "start_time": "2022-02-27T20:44:48.647751Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 11,  0, 16,  8, 13, 15])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes.flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb0ad9fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:48.675647Z",
     "start_time": "2022-02-27T20:44:48.662683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexes.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d32a0ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:48.691012Z",
     "start_time": "2022-02-27T20:44:48.677644Z"
    }
   },
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(len(boundary_boxes), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c90882e",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "# Draw Boundary Boxes,Write labels and probabilty of the image's objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e1ee3d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:51.306054Z",
     "start_time": "2022-02-27T20:44:48.693041Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in indexes.flatten():\n",
    "    x,y,w,h = boundary_boxes[i]\n",
    "    label = str(classes[predicted_classes[i]])\n",
    "    probability = str(round(probabilities[i], 2))\n",
    "    color = colors[i]\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "    cv2.putText(img, label + \" \" + probability, (x, y+20), font, 2, (0,255,0), 2)\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8993bd5",
   "metadata": {},
   "source": [
    "<a id='8'></a>\n",
    "# Detect Objects in a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655de4ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:44:53.654551Z",
     "start_time": "2022-02-27T20:44:51.307052Z"
    }
   },
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture('test1.mp4')\n",
    "while True:\n",
    "    _, img = vid.read()\n",
    "    height, width, channels = img.shape\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob) # set the input from the blob into the network\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames() # get the output layers names\n",
    "    layersOutput = net.forward(output_layers_names) # passing output layers names to forward network function we will get the output from this funciton\n",
    "    boundary_boxes = []\n",
    "    probabilities = []\n",
    "    predicted_classes = []\n",
    "    for output in layersOutput: # extract all the information from the layers output\n",
    "        for detection in output: # extract the information from each of the outputs\n",
    "            scores = detection[5:] # store all the acting classes predictions \n",
    "            class_id = np.argmax(scores) # store the locations that contains the higher scores\n",
    "            probability = scores[class_id] # extract the higher scores,\n",
    "            # bec. we want to make sure that thier their predictions has a confidence that is high enough to consider that the object has been detected\n",
    "            if probability > 0.5:\n",
    "                center_x = int(detection[0]*width) # scale it back\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "                # bec. yolo predicts the results with the center of the bounding boxes\n",
    "                # extract the upper left cornor position\n",
    "                x = int(center_x- w/2)\n",
    "                y = int(center_y- h/2)\n",
    "                boundary_boxes.append([x,y,w,h])\n",
    "                probabilities.append((float(probability)))\n",
    "                predicted_classes.append(class_id)\n",
    "    indexes = cv2.dnn.NMSBoxes(boundary_boxes, probabilities, 0.5, 0.4)\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    colors = np.random.uniform(0, 255, size=(len(boundary_boxes), 3))\n",
    "    if len(indexes)>0:\n",
    "        for i in indexes.flatten():\n",
    "            x,y,w,h = boundary_boxes[i]\n",
    "            label = str(classes[predicted_classes[i]])\n",
    "            probability = str(round(probabilities[i], 2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(img, label + \" \" + probability, (x, y+20), font, 2, (255,255,255), 2)\n",
    "    cv2.imshow('Image', img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf96bb7e",
   "metadata": {},
   "source": [
    "<a id='9'></a>\n",
    "# Detect Object Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360dab42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-27T20:45:32.235796Z",
     "start_time": "2022-02-27T20:44:53.655549Z"
    }
   },
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, img = vid.read()\n",
    "    height, width, channels = img.shape\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob) # set the input from the blob into the network\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames() # get the output layers names\n",
    "    layersOutput = net.forward(output_layers_names) # passing output layers names to forward network function we will get the output from this funciton\n",
    "    boundary_boxes = []\n",
    "    probabilities = []\n",
    "    predicted_classes = []\n",
    "    for output in layersOutput: # extract all the information from the layers output\n",
    "        for detection in output: # extract the information from each of the outputs\n",
    "            scores = detection[5:] # store all the acting classes predictions \n",
    "            class_id = np.argmax(scores) # store the locations that contains the higher scores\n",
    "            probability = scores[class_id] # extract the higher scores,\n",
    "            # bec. we want to make sure that thier their predictions has a confidence that is high enough to consider that the object has been detected\n",
    "            if probability > 0.5:\n",
    "                center_x = int(detection[0]*width) # scale it back\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "                # bec. yolo predicts the results with the center of the bounding boxes\n",
    "                # extract the upper left cornor position\n",
    "                x = int(center_x- w/2)\n",
    "                y = int(center_y- h/2)\n",
    "                boundary_boxes.append([x,y,w,h])\n",
    "                probabilities.append((float(probability)))\n",
    "                predicted_classes.append(class_id)\n",
    "    indexes = cv2.dnn.NMSBoxes(boundary_boxes, probabilities, 0.5, 0.4)\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    colors = np.random.uniform(0, 255, size=(len(boundary_boxes), 3))\n",
    "    if len(indexes)>0:\n",
    "        for i in indexes.flatten():\n",
    "            x,y,w,h = boundary_boxes[i]\n",
    "            label = str(classes[predicted_classes[i]])\n",
    "            probability = str(round(probabilities[i], 2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(img, label + \" \" + probability, (x, y+20), font, 2, (255,255,255), 2)\n",
    "    cv2.imshow('Image', img)\n",
    "    key = cv2.waitKey(100)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9803125",
   "metadata": {},
   "source": [
    "## by Mahmoud Abdelmoaty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5950be1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
